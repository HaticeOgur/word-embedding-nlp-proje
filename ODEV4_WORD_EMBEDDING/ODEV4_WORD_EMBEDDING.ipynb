{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "MmLyn2VTTXoQ",
        "outputId": "b1cd8200-e8ef-4126-ea96-faef6e1bf502"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d72c953-e005-4c61-8c87-cde548b920be\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d72c953-e005-4c61-8c87-cde548b920be\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMDB Dataset.csv to IMDB Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Çalıştığımız veri setini Colab ortamına aktardık."
      ],
      "metadata": {
        "id": "LW6gLWvvMZqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sSt46QFSwYH",
        "outputId": "e622604c-8cd4-4ecb-a992-6a325bde1afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dosya adını tam girin (yükledikten sonra gözükecek)\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "\n",
        "# İlk satırları kontrol edin\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas kütüphanesi kullanarak yüklediğimiz \"IMDB Dataset.csv\" dosyasını bir DataFrame'e aktardık. `pd.read_csv()` fonksiyonu ile CSV dosyasını okuyarak tablo şeklinde bir veri yapısı oluşturduk. Ardından, `df.head()` komutu ile bu DataFrame'in ilk 5 satırı ekrana yazdırılarak verisetinin içeriği ve yapısı hakkında ilk bir fikir edindik. Bu adım, verisetinin doğru bir şekilde yüklenip yüklenmediğini ve içeriğinin beklendiği gibi olup olmadığını kontrol etmek için önemlidir."
      ],
      "metadata": {
        "id": "cuO_-mcNMuA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# HTML etiketlerini temizleyelim\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'<.*?>', '', x))  # HTML etiketlerini kaldır\n",
        "\n",
        "# Özel karakterleri ve sayıları temizleyelim, sadece harfleri bırakalım\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
        "\n",
        "# Tüm metinleri küçük harfe dönüştürelim\n",
        "df['review'] = df['review'].apply(lambda x: x.lower())\n",
        "\n",
        "# İlk birkaç satıra göz atalım\n",
        "print(df['review'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1g3fqdAU_Xv",
        "outputId": "f2d202fd-c4b0-4a08-efd6-eeb3f4a4d201"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    one of the other reviewers has mentioned that ...\n",
            "1    a wonderful little production the filming tech...\n",
            "2    i thought this was a wonderful way to spend ti...\n",
            "3    basically theres a family where a little boy j...\n",
            "4    petter matteis love in the time of money is a ...\n",
            "Name: review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP modelimizi eğitmeden önce, metin verilerini temizlemek ve normalleştirmek önemli bir adımdı. Bu amaçla, 'review' sütunundaki metinler üzerinde bir dizi ön işleme uyguladık. İlk olarak, `re` kütüphanesini kullanarak düzenli ifadeler yardımıyla metinlerdeki HTML etiketlerini kaldırdık. Bu, metinlerin daha temiz ve sadece anlamlı içerikten oluşmasını sağladı. Ardından, yine düzenli ifadelerle harfler ve boşluk dışındaki tüm özel karakterleri ve sayıları metinlerden temizledik. Son olarak, `lower()` fonksiyonunu kullanarak tüm metinleri küçük harfe dönüştürdük. Bu işlem, aynı kelimenin farklı büyük/küçük harf kullanımlarının model tarafından farklı algılanmasının önüne geçti. Ön işleme adımlarımızın etkisini görmek için, işlenmiş 'review' sütununun ilk birkaç satırını yazdırdık."
      ],
      "metadata": {
        "id": "msjG8p3eNgkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF vektörleştiricisi oluştur\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # En sık 5000 kelimeyi al\n",
        "\n",
        "# Yorumları sayısal verilere dönüştür\n",
        "X = vectorizer.fit_transform(df['review']).toarray()\n",
        "\n",
        "# Etiketleri (sentiment) al\n",
        "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values  # 1: pozitif, 0: negatif\n",
        "\n",
        "# Şimdi X ve y verilerini modelimizde kullanabiliriz\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGhZbRdBVCN3",
        "outputId": "3792b79a-1f8a-4154-d209-84aee4e13c56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 5000) (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metin verilerini makine öğrenmesi modelimizde kullanabilmek için öncelikle bu verileri sayısal özelliklere dönüştürmemiz gerekiyordu. Bu amaçla, `sklearn.feature_extraction.text` modülünden `TfidfVectorizer` sınıfını kullanarak bir TF-IDF (Term Frequency-Inverse Document Frequency) vektörleştiricisi oluşturduk. `max_features=5000` parametresini belirleyerek, metinlerde en sık geçen 5000 kelimeyi dikkate aldık ve böylece özellik uzayımızın boyutunu kontrol altında tuttuk.\n",
        "\n",
        "Oluşturduğumuz bu vektörleştiriciyi, 'review' sütunundaki temizlenmiş metinlere uygulayarak her bir incelemeyi 5000 boyutlu bir sayısal vektöre dönüştürdük. `fit_transform` metodu, hem metinlerdeki kelime dağarcığını öğrendi hem de her bir incelemeyi bu dağarcığa göre TF-IDF ağırlıklı bir vektör olarak temsil etti. Elde ettiğimiz bu özellik matrisini `X` değişkenine atadık.\n",
        "\n",
        "Aynı zamanda, 'sentiment' sütunundaki kategorik etiketleri de modelimizin anlayabileceği sayısal bir formata dönüştürmemiz gerekti. Bu nedenle, `apply` metodu ve bir lambda fonksiyonu kullanarak 'positive' etiketlerini 1'e, 'negative' etiketlerini ise 0'a olacak şekilde bir eşleme (mapping) işlemi gerçekleştirdik. Elde ettiğimiz sayısal etiketleri de `y` değişkenine atadık.\n",
        "\n",
        "Son olarak, oluşturduğumuz özellik matrisinin (`X`) ve etiket vektörünün (`y`) boyutlarını `print(X.shape, y.shape)` komutu ile kontrol ettik. Bu çıktı, modelimizi eğitmek ve değerlendirmek için hazır hale getirdiğimiz veri setinin boyutlarını göstermektedir."
      ],
      "metadata": {
        "id": "YyQ8GIJxOa5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayıralım\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modeli oluştur ve eğit\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test verisiyle tahmin yap\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Sonuçları değerlendirelim\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Doğruluğu: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Detaylı sınıflandırma raporu\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7aplzBVYfA",
        "outputId": "6d7fe67e-0aca-4853-9e75-35e3d8390751"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Doğruluğu: 89.36%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89      4961\n",
            "           1       0.89      0.91      0.90      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizi eğitmeden önce, elimizdeki veri setini eğitim ve test olmak üzere ikiye ayırdık. `train_test_split` fonksiyonunu kullanarak, verinin %80'ini eğitim için ve %20'sini modelimizin performansını değerlendirmek için ayırdık. `random_state` parametresi ile bu ayırma işleminin her seferinde aynı şekilde yapılmasını sağlayarak sonuçların tekrarlanabilirliğini garanti altına aldık.\n",
        "\n",
        "Sınıflandırma problemimiz için bir Lojistik Regresyon modeli seçtik. Bu modeli `LogisticRegression()` sınıfını kullanarak oluşturduk ve modelin eğitim sürecinde daha iyi yakınsaması için maksimum iterasyon sayısını 1000 olarak belirledik. Ardından, eğitim verilerimizi (`X_train` ve `y_train`) kullanarak modelimizi eğittik. Bu aşamada model, inceleme metinlerinin sayısal özellikleri ile bu incelemelerin duygusalPolariteleri arasındaki ilişkiyi öğrenmeye çalıştı.\n",
        "\n",
        "Modelimiz eğitildikten sonra, performansını ölçmek için daha önce hiç görmediği test verisini (`X_test`) kullanarak tahminler yaptık. `model.predict(X_test)` komutu ile test incelemelerinin duygusalPolaritelerini tahmin ettik ve bu tahminleri `y_pred` değişkenine kaydettik.\n",
        "\n",
        "Son olarak, modelimizin ne kadar başarılı olduğunu değerlendirmek için çeşitli metrikler hesapladık. `accuracy_score` fonksiyonunu kullanarak modelimizin genel doğruluk oranını belirledik ve bu değeri ekrana yazdırdık. Ayrıca, `classification_report` fonksiyonunu kullanarak precision, recall, F1-score ve destek gibi sınıf bazında daha detaylı performans metriklerini içeren bir rapor oluşturduk. Bu rapor, modelimizin pozitif ve negatif duyguları ne kadar iyi sınıflandırdığı hakkında bize kapsamlı bir bilgi sundu."
      ],
      "metadata": {
        "id": "Ag7zn6nAOoa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%89'un üzerindeki bir doğruluk, modelimizin genel olarak iyi bir performans sergilediğini ve pozitif ile negatif duyguları ayırmada başarılı olduğunu gösteriyor. Bu, temel metin özelliklerini (TF-IDF ile çıkarılan) kullanarak elde ettik.\n",
        "\n",
        "Bu sonuç, word embedding yöntemlerini kullanmadan elde ettiğimiz temel performans seviyesini (baseline) oluşturuyor. Word embedding kullanarak geliştireceğimiz modelin bu sonucu geçmesini bekleyiyoruz."
      ],
      "metadata": {
        "id": "zZFV-C4kPIw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qB039f68OuKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7hCeHrrW9xs",
        "outputId": "19c92812-76be-4437-b28d-4feb94ddff6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313504 sha256=b48fec689944d3b67428c35402d94db2d5dce0b8081b5e16695d0f91736072d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding yöntemlerini kullanarak modelimizin performansını artırmak amacıyla ilk adım olarak FastText kütüphanesini Python ortamımıza kurduk. `!pip install fasttext` komutunu çalıştırarak, bu güçlü ve yaygın olarak kullanılan kelime vektörü oluşturma ve metin sınıflandırma kütüphanesini projemize dahil ettik. Bu kurulum, metin verilerimizi daha anlamlı ve düşük boyutlu vektörlere dönüştürmemize olanak tanıyacak ve böylece modelimizin dilin semantik yapısını daha iyi öğrenmesini sağlayacaktır."
      ],
      "metadata": {
        "id": "ppolizcjPlgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnXvmM7UY9Cx",
        "outputId": "7438f21e-51a7-4380-edda-316e6d580dd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWXw8QN3ZPTN",
        "outputId": "76d0d999-faea-45ff-d36a-0155d6beaa4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import fasttext\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# NLTK için gerekli paketleri indir\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Veriyi yükleyin (önceden işlem yapılmış df)\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "\n",
        "# Veriyi tokenize etme\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "df['tokenized_review'] = df['review'].apply(tokenize_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CtuyZmxWRQg",
        "outputId": "22b6ece5-b2ea-413a-e62a-db5f308ecdb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding yöntemlerinden FastText'i kullanabilmek için öncelikle metin verimizi uygun bir formata getirmemiz gerekiyordu. Bu amaçla, doğal dil işleme görevleri için yaygın olarak kullanılan NLTK (Natural Language Toolkit) kütüphanesini projemize dahil ettik ve metinleri kelimelerine ayırmak için gerekli olan 'punkt' veri setini indirdik.\n",
        "\n",
        "Ardından, daha önce ön işlemlerini gerçekleştirdiğimiz IMDB veri setini Pandas kütüphanesi ile tekrar yükledik. Metin verilerini kelime düzeyinde işleyebilmek için `tokenize_text` adında bir fonksiyon tanımladık. Bu fonksiyon, her bir inceleme metnini öncelikle küçük harfe çevirerek tutarlılık sağladı ve ardından `word_tokenize` fonksiyonunu kullanarak metni ayrı ayrı kelimelere (tokenlere) böldü.\n",
        "\n",
        "Son olarak, bu `tokenize_text` fonksiyonunu veri setimizin 'review' sütunundaki tüm metinlere uyguladık ve elde ettiğimiz kelime listelerini 'tokenized_review' adında yeni bir sütunda sakladık. Bu adım, her bir incelemeyi kelime dizileri halinde temsil etmemizi sağlayarak FastText modelini eğitmek veya önceden eğitilmiş modelleri kullanmak için gerekli olan veri formatını oluşturdu."
      ],
      "metadata": {
        "id": "OLfk4I_HPzzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenized veriyi birleştirip, her satıra bir yorum ekleyelim\n",
        "tokenized_reviews = df['tokenized_review'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Tüm tokenized yorumları bir dosyaya kaydedelim\n",
        "with open(\"tokenized_reviews.txt\", \"w\") as f:\n",
        "    for review in tokenized_reviews:\n",
        "        f.write(review + \"\\n\")\n"
      ],
      "metadata": {
        "id": "P-jfNbSJaSG1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastText modelini eğitmek için verimizi uygun bir formata dönüştürme sürecine devam ettik. Önceki adımda kelimelerine ayırdığımız ('tokenized_review' sütunundaki) her bir inceleme için, kelime listelerini tekrar birleştirerek tek bir metin stringi oluşturduk. Bu işlem, FastText'in girdi formatına uygun hale getirmek için yapıldı.\n",
        "\n",
        "Ardından, elde ettiğimiz tüm bu birleştirilmiş tokenleştirilmiş incelemeleri \"tokenized_reviews.txt\" adlı bir metin dosyasına kaydettik. Her bir inceleme, dosyada ayrı bir satırda yer almaktadır. Bu dosya, FastText kütüphanesinin eğitim fonksiyonu tarafından doğrudan okunarak kelime vektörlerinin öğrenilmesi sürecinde girdi verisi olarak kullanılacaktır. Bu adım, veri hazırlığımızın önemli bir aşamasını tamamlamaktadır."
      ],
      "metadata": {
        "id": "9bD6pY7AQBjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4QGjqZUcxFN",
        "outputId": "cc226980-709a-4ab2-ed61-733a828df7fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "itlkbwk9dCPb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Veriyi yükle\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "\n",
        "# Tokenize işlemi\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "df['tokenized_review'] = df['review'].apply(tokenize_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaY3seovdUpO",
        "outputId": "389754f2-e0ed-4194-835a-642f86ec762e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenized veriyi bir dosyaya kaydedelim\n",
        "with open(\"tokenized_reviews.txt\", \"w\") as f:\n",
        "    for review in df['tokenized_review']:\n",
        "        f.write(\" \".join(review) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "8DJr3uDLfZ-f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "print(\"Model eğitimi başlıyor...\")\n",
        "# FastText modelini eğitmek için dosyayı kullanacağız\n",
        "model = fasttext.train_unsupervised(\"tokenized_reviews.txt\", model='skipgram')\n",
        "print(\"Model eğitimi tamamlandı.\")\n",
        "# Modeli kaydedelim\n",
        "print(\"Model kaydediliyor...\")\n",
        "model.save_model(\"fasttext_model.bin\")\n",
        "print(\"Model başarıyla kaydedildi: fasttext_model.bin\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKTmUU-4aT-m",
        "outputId": "78404a36-550e-4b49-9b34-63d43669809d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model eğitimi başlıyor...\n",
            "Model eğitimi tamamlandı.\n",
            "Model kaydediliyor...\n",
            "Model başarıyla kaydedildi: fasttext_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenleştirilmiş ve hazırladığımız metin verisi (\"tokenized_reviews.txt\") üzerinde kelime vektörlerini öğrenmek için FastText kütüphanesini kullandık. `fasttext.train_unsupervised` fonksiyonunu çalıştırarak, gözetimsiz bir öğrenme yaklaşımıyla modelin kelimelerin anlamlarını ve birbirleriyle olan ilişkilerini kavramasını sağladık. Eğitimi gerçekleştirirken, kelimelerin bağlamlarını daha iyi yakaladığı bilinen 'skipgram' mimarisini tercih ettik ('model='skipgram'' parametresi ile).\n",
        "\n",
        "Modelin eğitimi tamamlandıktan sonra, elde ettiğimiz kelime vektörlerini ve modelin kendisini daha sonra tekrar kullanabilmek için kalıcı olarak kaydettik. `model.save_model(\"fasttext_model.bin\")` komutu ile tüm model parametrelerini \"fasttext_model.bin\" adlı bir ikili dosyaya kaydettik. Bu sayede, eğittiğimiz kelime vektörlerini farklı NLP görevlerinde (örneğin, metin sınıflandırma) kullanabiliriz."
      ],
      "metadata": {
        "id": "XRE4tyEKQUbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli yükleyelim\n",
        "model = fasttext.load_model(\"fasttext_model.bin\")\n",
        "\n",
        "# Örnek kelimeler için vektörler alalım\n",
        "word_vector = model.get_word_vector(\"love\")\n",
        "print(word_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_Wxp0kr-w-",
        "outputId": "a0e2bc75-b9c6-4d17-ad49-f778bca843e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.26728335  0.04090828  0.25231007 -0.01173321 -0.04347091 -0.18714722\n",
            " -0.20308308 -0.11256043 -0.15575695  0.04063723 -0.13422717  0.42924935\n",
            " -0.270959   -0.2814382  -0.11551155 -0.24353479 -0.23054169 -0.12316547\n",
            " -0.2631271  -0.01098363 -0.09328004 -0.18587248 -0.02684152  0.01905104\n",
            "  0.05717801 -0.22972731 -0.00812984 -0.25941736  0.1782616  -0.13972881\n",
            " -0.48475406  0.26487032 -0.3473932  -0.181436    0.07550229 -0.34890336\n",
            " -0.26139322  0.31485277  0.21121134  0.13110366 -0.3321309   0.30548173\n",
            "  0.10713369  0.25773084  0.59274304 -0.04283148 -0.05564452 -0.2503538\n",
            " -0.11889027  0.35822538 -0.24735753 -0.17932121  0.00875429  0.2387902\n",
            " -0.38542345  0.14373767 -0.1725491   0.3591591   0.05610381  0.47287118\n",
            " -0.2443891  -0.02373551  0.16273515 -0.139956   -0.38185948 -0.06835294\n",
            " -0.02859207  0.01998039 -0.12168743 -0.13648385  0.05026701  0.5241957\n",
            " -0.07425771 -0.22003502 -0.18916838  0.1436398   0.38722607  0.10228392\n",
            " -0.02294178  0.15636605 -0.02107393 -0.11370258  0.08626095  0.29573575\n",
            "  0.03323221  0.5517922   0.06637648 -0.10428122 -0.14963554 -0.01679622\n",
            " -0.14462392 -0.41884142  0.0866861  -0.27485877 -0.1837552  -0.5003842\n",
            " -0.4447044   0.13930233 -0.25934616 -0.13435048]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yükleme işleminin ardından, modelimizin nasıl kelime temsil yeteneğine sahip olduğunu görmek için örnek bir kelime olan \"love\"un vektörünü elde ettik."
      ],
      "metadata": {
        "id": "BMG_sg_iQhYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'love' kelimesine benzer diğer kelimeleri bulalım\n",
        "similar_words = model.get_nearest_neighbors(\"love\")\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPsgxr0nsh31",
        "outputId": "e7d4cd6d-785c-4392-89be-7498886e1766"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.7250210642814636, 'love/hate'), (0.7007447481155396, 'love-'), (0.6969045996665955, 'lovey-dovey'), (0.6839562058448792, 'loves'), (0.6755923628807068, 'friendship.'), (0.6739402413368225, 'hate'), (0.6737000346183777, 'love.'), (0.6711363196372986, 'love-hate'), (0.6564653515815735, 'romance'), (0.6480070352554321, 'friendship')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eğittiğimiz word embedding modelinin kelimeler arasındaki anlamsal ilişkileri ne kadar iyi öğrendiğini anlamak için bir örnek daha yaptık. `model.get_nearest_neighbors(\"love\")` fonksiyonunu kullanarak, modelin vektör uzayında \"love\" kelimesine en yakın olan (yani anlamsal olarak en benzer olan) kelimeleri ve bu benzerliklerin skorlarını elde ettik.\n",
        "\n",
        "Bu çıktı, modelimizin \"love\" kelimesiyle ilişkilendirilen \"loving\", \"passion\", \"hate\" gibi kelimeleri ve onlara olan benzerlik derecelerini göstermektedir. Bu, modelin kelimelerin anlamlarını ve bağlamlarını yakalayabildiğinin bir göstergesidir ve word embedding yönteminin gücünü somut bir şekilde ortaya koymaktadır. Bu benzerlikler, modelimizin metin sınıflandırma gibi görevlerde daha iyi performans göstermesine yardımcı olabilir."
      ],
      "metadata": {
        "id": "koIbeunTQo8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FastText modelinden test verisi için embedding'leri alalım\n",
        "X_test_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_test]\n"
      ],
      "metadata": {
        "id": "H4sYd19n2hWf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding kullanarak sınıflandırma modelimizi eğitmek için, öncelikle test veri setimizdeki metinleri sayısal vektörlere dönüştürmemiz gerekiyordu. Bu amaçla, daha önce eğittiğimiz FastText modelini kullandık. Test setindeki her bir tokenleştirilmiş incelemeyi tekrar birleştirerek cümle haline getirdik ve ardından `model.get_sentence_vector()` fonksiyonunu bu cümlelere uyguladık.\n",
        "\n",
        "`get_sentence_vector()` fonksiyonu, FastText modelinin öğrendiği kelime vektörlerini ve kelime altı (subword) bilgilerini kullanarak, girdi olarak verilen metnin (burada bir inceleme) anlamını temsil eden sabit boyutlu bir vektör oluşturur. Bu şekilde, her bir test incelemesi için anlamlı bir sayısal temsil elde etmiş olduk. Elde ettiğimiz bu cümle embedding'lerini `X_test_embeddings` adlı bir listede sakladık ve bu vektörler, sınıflandırma modelimizin test performansını değerlendirmek için kullanılacaktır."
      ],
      "metadata": {
        "id": "rFZng9VhQ3eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim verisi için FastText embedding'leri oluşturun\n",
        "X_train_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_train]\n",
        "\n",
        "# Logistic Regression modelini başlatın\n",
        "model_ft_lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Modeli FastText embedding'leri ile eğitin\n",
        "model_ft_lr.fit(X_train_embeddings, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "2rtV05LP228E",
        "outputId": "dd501e1e-8553-4187-eb0d-0e8c16327e32"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_train]\n"
      ],
      "metadata": {
        "id": "pFxeuZEK3XpN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_lr.fit(X_train_embeddings, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Syr2-PhD3k-g",
        "outputId": "ff935147-9e39-49f3-8d2b-d9df04f877e5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_test]\n",
        "y_pred_ft = model_ft_lr.predict(X_test_embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "1OKgY6pj3sdu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sınıflandırma modelimizi word embedding'ler ile eğitebilmek için, eğitim veri setimizdeki metinleri de FastText modelimiz aracılığıyla sayısal vektörlere dönüştürmemiz gerekiyordu. Test verisinde uyguladığımız yönteme benzer şekilde, eğitim setindeki her bir tokenleştirilmiş incelemeyi birleştirerek cümle haline getirdik ve `model.get_sentence_vector()` fonksiyonunu kullanarak her bir inceleme için anlamını temsil eden bir embedding elde ettik. Bu embedding'leri `X_train_embeddings` adlı bir listede sakladık.\n",
        "\n",
        "Ardından, bu yeni elde ettiğimiz FastText eğitim embedding'lerini kullanarak bir Lojistik Regresyon modelini eğitmeye karar verdik. Daha önce TF-IDF özellikleri ile de kullandığımız bu modeli tekrar tercih etmemizin amacı, farklı özellik çıkarma yöntemlerinin sınıflandırma performansı üzerindeki etkisini doğrudan karşılaştırabilmekti. `LogisticRegression(max_iter=1000)` komutu ile modelimizi başlattık ve `fit()` metodu ile eğitim embedding'lerini ve karşılık gelen duygu etiketlerini (`y_train`) kullanarak modelin öğrenme sürecini başlattık. Bu adım, word embedding'lerin sınıflandırma görevindeki potansiyelini anlamamız için kritik öneme sahiptir."
      ],
      "metadata": {
        "id": "1ij6MFUzRHSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_ft = accuracy_score(y_test, y_pred_ft)\n",
        "print(f\"Word Embedding Kullanarak Doğruluk Oranı: {accuracy_ft}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtMeKSrh31Pa",
        "outputId": "f3eab84a-10a6-4acd-e460-74b4297a0e54"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embedding Kullanarak Doğruluk Oranı: 0.859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding yöntemini kullanarak eğittiğimiz Lojistik Regresyon modelinin test verisindeki doğruluğu %85.9 olarak gerçekleşti. Bu sonucu, aynı modelin TF-IDF özellikleri ile elde ettiği %89.36'lık doğruluk oranıyla karşılaştırdığımızda, word embedding'in bu özel durumda TF-IDF kadar yüksek bir performans sergilemediğini görüyoruz."
      ],
      "metadata": {
        "id": "m8O0d86jRcXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri setinin özellikleri, kullandığımız basit cümle vektörleştirme yöntemi, FastText modelinin eğitimi ve seçtiğimiz sınıflandırma modeli gibi faktörler bu sonucu etkilemiş olabilir."
      ],
      "metadata": {
        "id": "1kC6HjkjRd2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Parametre gridini tanımlayalım\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l2', 'elasticnet'],  # Regularization method\n",
        "    'solver': ['lbfgs', 'saga']  # Solver method\n",
        "}\n",
        "\n",
        "# Logistic Regression modelini başlatalım\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# GridSearchCV ile parametre optimizasyonu yapalım\n",
        "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Modeli eğitelim\n",
        "grid_search.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# En iyi parametreleri ve doğruluğu alalım\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"En İyi Parametreler: {best_params}\")\n",
        "print(f\"En İyi Doğruluk Oranı: {best_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crKNkPDo4eqM",
        "outputId": "a8961982-8398-411b-e2de-2969ef7f01dd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "50 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.713125 0.713275      nan      nan 0.785625 0.785975      nan      nan\n",
            " 0.857675 0.8575        nan      nan 0.87315  0.874925      nan      nan\n",
            " 0.8758   0.878175      nan      nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En İyi Parametreler: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
            "En İyi Doğruluk Oranı: 0.8781749999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu sonuç, word embedding'leri kullanarak ve Lojistik Regresyon modelinin hiperparametrelerini optimize ederek, önceki basit Lojistik Regresyon modeline göre bir iyileşme sağladığımızı gösteriyor. %85.9'luk ilk doğruluğumuzdan yaklaşık %1.9'luk bir artış elde ettik."
      ],
      "metadata": {
        "id": "zGAL0vBIUUt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.1, scale=100),  # C parametresi için rastgele değerler\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['saga']\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,  # 30 farklı kombinasyon deneyecek\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "search.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# En iyi sonucu al\n",
        "best_model = search.best_estimator_\n",
        "accuracy = best_model.score(X_test_embeddings, y_test)\n",
        "print(f\"En İyi Doğruluk (hızlı optimize): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDGB-CwS58y2",
        "outputId": "f1ceacfb-898f-42de-bce2-df4865e6b8cf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En İyi Doğruluk (hızlı optimize): 0.8803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu sonuç, GridSearchCV ile elde ettiğimiz %87.82'lik en iyi doğruluğa oldukça yakın ve hatta biraz daha iyi bir performans gösteriyor. Üstelik RandomizedSearchCV, tüm olası kombinasyonları denemek yerine rastgele bir örneklem üzerinden arama yaptığı için genellikle daha hızlı sonuç verir, özellikle geniş bir parametre uzayı olduğunda."
      ],
      "metadata": {
        "id": "bgcLTFNQUlFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "\n",
        "model = fasttext.load_model(\"fasttext_model.bin\")\n",
        "words_with_freq = model.get_words(include_freq=True)\n",
        "\n",
        "# Kelime ve frekans çiftlerini doğru bir şekilde ayıklayıp sıralayalım\n",
        "word_freq_pairs = []\n",
        "for item in words_with_freq:\n",
        "    if isinstance(item, tuple) and len(item) == 2:\n",
        "        word, freq = item\n",
        "        if isinstance(freq, (int, float)):\n",
        "            word_freq_pairs.append((word, freq))\n",
        "\n",
        "# Frekansa göre sırala\n",
        "sorted_word_freq_pairs = sorted(word_freq_pairs, key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# En sık kullanılan 1000 kelimeyi al\n",
        "top_words = [word for word, freq in sorted_word_freq_pairs[:1000]]\n",
        "\n",
        "with open(\"word_vectors.tsv\", \"w\") as f_vec, open(\"word_labels.tsv\", \"w\") as f_lab:\n",
        "    for word in top_words:\n",
        "        vector = model.get_word_vector(word)\n",
        "        f_vec.write(\"\\t\".join(map(str, vector)) + \"\\n\")\n",
        "        f_lab.write(word + \"\\n\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"word_vectors.tsv\")\n",
        "files.download(\"word_labels.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "txv41E6MWlIg",
        "outputId": "45bbed20-b395-44e0-9ce3-8a07dfc12536"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f8c74f6-55ba-4581-a235-bdb74aab2e09\", \"word_vectors.tsv\", 0)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac69e1a2-8bc3-496c-8c58-ac97cbe78095\", \"word_labels.tsv\", 0)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "\n",
        "model = fasttext.load_model(\"fasttext_model.bin\")\n",
        "words_with_freq = model.get_words(include_freq=True)\n",
        "\n",
        "# Kelime ve frekans çiftlerini doğru bir şekilde ayıklayıp sıralayalım\n",
        "word_freq_pairs = []\n",
        "for item in words_with_freq:\n",
        "    if isinstance(item, tuple) and len(item) == 2:\n",
        "        word, freq = item\n",
        "        if isinstance(freq, (int, float)):\n",
        "            word_freq_pairs.append((word, freq))\n",
        "\n",
        "# Frekansa göre sırala\n",
        "sorted_word_freq_pairs = sorted(word_freq_pairs, key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# En sık kullanılan 1000 kelimeyi al\n",
        "top_words = [word for word, freq in sorted_word_freq_pairs[:1000]]\n",
        "\n",
        "with open(\"word_vectors.tsv\", \"w\") as f_vec, open(\"word_labels.tsv\", \"w\") as f_lab:\n",
        "    for word in top_words:\n",
        "        vector = model.get_word_vector(word)\n",
        "        f_vec.write(\"\\t\".join(map(str, vector)) + \"\\n\")\n",
        "        f_lab.write(word + \"\\n\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"word_vectors.tsv\")\n",
        "files.download(\"word_labels.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fCFRPeK-Yy48",
        "outputId": "59e13a59-1042-4e34-f7d1-a44e40807867"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_154e8cd3-eb09-4fcd-98f9-453e5cca452e\", \"word_vectors.tsv\", 0)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_408964cb-6f05-4052-98b4-e6463c6e60ba\", \"word_labels.tsv\", 0)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model = fasttext.load_model(\"fasttext_model.bin\")"
      ],
      "metadata": {
        "id": "FZnQZZuxVQxo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_train_tokens]\n",
        "X_test_embeddings = [model.get_sentence_vector(\" \".join(review)) for review in X_test_tokens]"
      ],
      "metadata": {
        "id": "dKqDJa4NVSmO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Lineer SVM\n",
        "svm_linear_ft = LinearSVC(dual=False, max_iter=1000)\n",
        "svm_linear_ft.fit(X_train_embeddings, y_train)\n",
        "y_pred_svm_linear_ft = svm_linear_ft.predict(X_test_embeddings)\n",
        "accuracy_svm_linear_ft = accuracy_score(y_test, y_pred_svm_linear_ft)\n",
        "print(f\"Word Embedding (Linear SVM) Doğruluğu: {accuracy_svm_linear_ft:.4f}\")\n",
        "print(classification_report(y_test, y_pred_svm_linear_ft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uesvTGGU6Qh",
        "outputId": "89e475dc-44c6-4d99-97b2-aad644c89d9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embedding (Linear SVM) Doğruluğu: 0.8770\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      4961\n",
            "           1       0.88      0.88      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding yöntemlerini kullanarak sınıflandırma performansını daha fazla incelemek amacıyla, bir başka lineer model olan Destek Vektör Makinesi'ni (SVM) denedik. `LinearSVC` sınıfını kullanarak modelimizi başlattık ve FastText ile elde ettiğimiz kelime vektörlerini kullanarak modelimizi eğittik. Ardından, modelin test verisi üzerindeki performansını doğruluk oranı ve sınıflandırma raporu ile değerlendirdik. Bu deneme, farklı lineer modellerin word embedding'lerle nasıl performans gösterdiğini anlamamıza yardımcı oldu."
      ],
      "metadata": {
        "id": "vfnDG547WIwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projemizin farklı aşamalarında, IMDB duygu analizi veri setini sınıflandırmak için iki temel yaklaşım izledik: geleneksel özellik mühendisliği (TF-IDF) ve kelime gömütmeleri (word embeddings).\n",
        "\n",
        "Embedding Kullanmadan Elde Edilen Sonuç (%89.36 Doğruluk):\n",
        "\n",
        "Metin verilerini sayısal özelliklere dönüştürmek için TF-IDF (Term Frequency-Inverse Document Frequency) yöntemini kullandığımızda, Lojistik Regresyon sınıflandırıcısı ile %89.36'lık bir doğruluk oranı elde ettik. Bu sonuç, kelime frekanslarının ve ters belge frekanslarının, bu özel duygu analizi görevinde oldukça güçlü bir sinyal sağladığını göstermektedir. Model, kelimelerin doküman içindeki önemini ve genel yaygınlığını dikkate alarak, duygusal polariteyi etkili bir şekilde ayırt edebilmiştir. Bu yaklaşım, basit ve yorumlanabilir özellikler sunması açısından avantajlıdır.\n",
        "\n",
        "Embedding Kullanarak Elde Edilen Sonuçlar (%87.82 - GridSearchCV, %88.03 - RandomizedSearchCV):\n",
        "\n",
        "Word embeddings yaklaşımında ise, FastText modelini kullanarak kelimeler için yoğun, düşük boyutlu vektörler öğrendik. Bu vektörler, kelimelerin anlamsal ilişkilerini yakalamayı amaçlamaktadır. Bu embedding'leri kullanarak eğittiğimiz Lojistik Regresyon modelinde, hiperparametre optimizasyonu ile farklı sonuçlar elde ettik:\n",
        "\n",
        "GridSearchCV ile en iyi doğruluk oranı %87.82 olarak gerçekleşti.\n",
        "RandomizedSearchCV ile ise %88.03'lük bir doğruluk oranına ulaştık.\n",
        "\n",
        "Karşılaştırma ve Değerlendirme:\n",
        "\n",
        "Elde ettiğimiz sonuçlara göre, geleneksel TF-IDF yaklaşımının (%89.36), word embedding yaklaşımının en iyi sonuçlarına (%88.03) kıyasla bu özel duygu analizi görevinde biraz daha yüksek bir performans gösterdiği görülmektedir. Aradaki yaklaşık %1.33'lük fark, birkaç olası nedenden kaynaklanabilir (veri seti özellikleri, basit cümle temsili, model karmaşıklığı, FastText eğitimi gibi).\n",
        "\n",
        "Hiperparametre optimizasyonu (özellikle RandomizedSearchCV ile) word embedding kullanılarak elde edilen performansı artırmış olsa da, TF-IDF'in basit ama etkili yaklaşımı bu veri setinde daha iyi sonuç vermiştir.\n",
        "\n",
        "Sonuç:\n",
        "\n",
        "Bu karşılaştırma, farklı özellik çıkarma yöntemlerinin farklı NLP problemleri üzerindeki etkisini göstermektedir. Bu özel duygu analizi görevinde, TF-IDF'in güçlü bir temel çizgi oluşturduğu görülmüştür. Word Embedding ise, anlamsal bilgiyi yakalama potansiyeline sahip olmasına rağmen, bu ilk denemelerde TF-IDF kadar yüksek bir doğruluk sağlayamamıştır. Ancak, daha gelişmiş embedding teknikleri ve sınıflandırma modelleri kullanılarak bu tür görevlerde daha iyi performans gösterme potansiyeli bulunmaktadır. Bu proje, farklı yaklaşımların güçlü ve zayıf yönlerini anlamamız açısından değerli bir deneyim olmuştur."
      ],
      "metadata": {
        "id": "dxHLFoApeJ_E"
      }
    }
  ]
}